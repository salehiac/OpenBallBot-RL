algo:
  name: ppo 
  ent_coef: 0.001
  clip_range: 0.015
  target_kl: 0.3
  vf_coef: 2.0
  learning_rate: -1 #this turns on the scheduler
  n_steps: 2048 #n_steps means n_steps per env before update
  weight_decay: 0.01 #not part of standard PPO
  n_epochs: 5
  batch_sz: 256
  normalize_advantage: false
problem:
  terrain_type: "perlin" #options are "perlin" and "flat"
total_timesteps: 10e6
frozen_cnn: "../encoder_frozen/encoder_epoch_53" #this model has been trained with snoise
hidden_sz: 128
num_envs: 10
resume: ""
out: ./log
seed: 10
